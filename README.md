# Neural-Network

This is a machine learning project that uses neural network on two different datasets to classify into one of the 
available categories based on the provided data.

### Dataset

1. IRIS Dataset : https://www.kaggle.com/uciml/iris
2. Breast Cancer Wisconsin Dataset: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data

### Process

"train_and_test.py" is the python file that is responsible for reading the data and pre-processing it. It also
normalizes the data for sigmoid function. It splits the data into train and test datasets. After all the pre-processing,
it creates an instance of NeuralNetwork class and adds necessary layers and neurons. It then trains the model in train
dataset and tests the validity on test dataset.\

nn.py is the implementation of the neural network. I have used sigmoid function as the activation function for the
neural network. NeuralNetwork class includes various functions that perform specific tasks. The "train" function
receives dataset, targets, number of iterations as parameters. It loops through the dataset for the number of iterations
and perform feed_forward and feed_backward functions and updates the weights accordingly. After it finishes each iteration,
it calculates the total_error. total_error decereases as it goes through more iterations. I have trained the model for 
100 iterations. "feed_forward" function is basically traversing the neural network from input layer to the output 
layer by predicting a value. On the other hand, "feed_backward" function makes the network actually learn by computing gradients 
and pushing them back through the network and finally updating the model parameters.


### Result

For IRIS Dataset\

```
> Training...
| # 1/100	|  Total error: 0.8505936907273343
| # 2/100	|  Total error: 0.547085937520715
| # 3/100	|  Total error: 0.4903052579718907
| # 4/100	|  Total error: 0.452946042503218
| # 5/100	|  Total error: 0.42492587896302725
| # 6/100	|  Total error: 0.403345203497655
| # 7/100	|  Total error: 0.38631202684449334
| # 8/100	|  Total error: 0.37254239039135234
| # 9/100	|  Total error: 0.3611638929274395
| # 10/100	|  Total error: 0.3515763062794861
| # 11/100	|  Total error: 0.3433590119812629
| # 12/100	|  Total error: 0.33621126712691624
| # 13/100	|  Total error: 0.3299137064303862
| # 14/100	|  Total error: 0.3243032582769255
| # 15/100	|  Total error: 0.31925653654001773
| # 16/100	|  Total error: 0.31467864608256074
| # 17/100	|  Total error: 0.3104954995270704
| # 18/100	|  Total error: 0.3066484505369872
| # 19/100	|  Total error: 0.3030904821334347
| # 20/100	|  Total error: 0.2997834567417631
| # 21/100	|  Total error: 0.2966961030193795
| # 22/100	|  Total error: 0.2938025218791156
| # 23/100	|  Total error: 0.2910810636946713
| # 24/100	|  Total error: 0.288513474477508
| # 25/100	|  Total error: 0.2860842394344738
| # 26/100	|  Total error: 0.2837800730876955
| # 27/100	|  Total error: 0.2815895194277599
| # 28/100	|  Total error: 0.27950263553156696
| # 29/100	|  Total error: 0.2775107391059777
| # 30/100	|  Total error: 0.2756062054383124
| # 31/100	|  Total error: 0.27378230285930527
| # 32/100	|  Total error: 0.27203305846853776
| # 33/100	|  Total error: 0.27035314782074127
| # 34/100	|  Total error: 0.26873780372018125
| # 35/100	|  Total error: 0.2671827403571948
| # 36/100	|  Total error: 0.2656840898429851
| # 37/100	|  Total error: 0.2642383488254281
| # 38/100	|  Total error: 0.26284233334986973
| # 39/100	|  Total error: 0.261493140501066
| # 40/100	|  Total error: 0.26018811565217304
| # 41/100	|  Total error: 0.2589248243737215
| # 42/100	|  Total error: 0.2577010282344674
| # 43/100	|  Total error: 0.25651466386791716
| # 44/100	|  Total error: 0.25536382479142883
| # 45/100	|  Total error: 0.25424674555548793
| # 46/100	|  Total error: 0.2531617878737731
| # 47/100	|  Total error: 0.2521074284437789
| # 48/100	|  Total error: 0.25108224821583996
| # 49/100	|  Total error: 0.250084922907705
| # 50/100	|  Total error: 0.24911421459404423
| # 51/100	|  Total error: 0.2481689642268446
| # 52/100	|  Total error: 0.24724808496463413
| # 53/100	|  Total error: 0.24635055620672627
| # 54/100	|  Total error: 0.24547541824390473
| # 55/100	|  Total error: 0.24462176744970757
| # 56/100	|  Total error: 0.24378875194715977
| # 57/100	|  Total error: 0.2429755676948262
| # 58/100	|  Total error: 0.24218145494367072
| # 59/100	|  Total error: 0.2414056950226715
| # 60/100	|  Total error: 0.2406476074166445
| # 61/100	|  Total error: 0.23990654710441472
| # 62/100	|  Total error: 0.2391819021294965
| # 63/100	|  Total error: 0.23847309137888126
| # 64/100	|  Total error: 0.23777956254851315
| # 65/100	|  Total error: 0.23710079027657693
| # 66/100	|  Total error: 0.23643627442794696
| # 67/100	|  Total error: 0.23578553851506773
| # 68/100	|  Total error: 0.23514812824220205
| # 69/100	|  Total error: 0.23452361016144302
| # 70/100	|  Total error: 0.23391157043015873
| # 71/100	|  Total error: 0.23331161366064995
| # 72/100	|  Total error: 0.23272336185378206
| # 73/100	|  Total error: 0.23214645340921014
| # 74/100	|  Total error: 0.23158054220557556
| # 75/100	|  Total error: 0.23102529674472003
| # 76/100	|  Total error: 0.23048039935455747
| # 77/100	|  Total error: 0.22994554544576995
| # 78/100	|  Total error: 0.22942044281795368
| # 79/100	|  Total error: 0.2289048110112674
| # 80/100	|  Total error: 0.22839838069999405
| # 81/100	|  Total error: 0.2279008931247665
| # 82/100	|  Total error: 0.22741209956049643
| # 83/100	|  Total error: 0.22693176081731603
| # 84/100	|  Total error: 0.22645964677207667
| # 85/100	|  Total error: 0.2259955359281622
| # 86/100	|  Total error: 0.22553921500157015
| # 87/100	|  Total error: 0.225090478531385
| # 88/100	|  Total error: 0.22464912851292201
| # 89/100	|  Total error: 0.22421497405197027
| # 90/100	|  Total error: 0.2237878310386804
| # 91/100	|  Total error: 0.22336752183976838
| # 92/100	|  Total error: 0.22295387500780803
| # 93/100	|  Total error: 0.22254672500647904
| # 94/100	|  Total error: 0.22214591195073105
| # 95/100	|  Total error: 0.22175128136089708
| # 96/100	|  Total error: 0.2213626839298672
| # 97/100	|  Total error: 0.22097997530249505
| # 98/100	|  Total error: 0.2206030158664775
| # 99/100	|  Total error: 0.22023167055399506
| # 100/100	|  Total error: 0.21986580865345898
Training Finish. Error = 0.21986580865345898


> Testing...
[#0] [0.25       0.875      0.08474576 0.        ] -> [0.9751533033930438, 0.05380607560871342, 0.002112457865029212] (targets=[1 0 0]) 0, 0
[#1] [0.47222222 0.08333333 0.50847458 0.375     ] -> [0.05714369343512569, 0.73493525994394, 0.165171225280036] (targets=[0 1 0]) 1, 1
[#2] [0.5        0.375      0.62711864 0.54166667] -> [0.04356877318394764, 0.40664446718270353, 0.34107295698950996] (targets=[0 1 0]) 1, 1
[#3] [0.36111111 0.41666667 0.59322034 0.58333333] -> [0.059797446842767894, 0.33496422414026694, 0.32676316455822785] (targets=[0 1 0]) 1, 1
[#4] [0.66666667 0.41666667 0.6779661  0.66666667] -> [0.017944239039782116, 0.338344801729632, 0.579338590687749] (targets=[0 1 0]) 2, 1
[#5] [0.66666667 0.45833333 0.62711864 0.58333333] -> [0.03621313239376591, 0.30283833429679285, 0.4141578007649769] (targets=[0 1 0]) 2, 1
[#6] [0.55555556 0.125      0.57627119 0.5       ] -> [0.025552026782621553, 0.6812969206164219, 0.33602070200986206] (targets=[0 1 0]) 1, 1
[#7] [0.61111111 0.41666667 0.81355932 0.875     ] -> [0.004545594100150963, 0.32461523769464684, 0.8614351738173757] (targets=[0 0 1]) 2, 2
[#8] [0.94444444 0.25       1.         0.91666667] -> [0.0005655244892501343, 0.5736388182162311, 0.9594967069817051] (targets=[0 0 1]) 2, 2
[#9] [0.47222222 0.08333333 0.6779661  0.58333333] -> [0.011842898568346714, 0.7339000940894794, 0.5114487954461554] (targets=[0 0 1]) 1, 2
Testing Finish. Error: 0.40077253102353455

Testing accuracy: 0.7\
```
Breast Cancer Wisconsin Dataset\

```
> Training...
| # 1/100	|  Total error: 0.02194823130494166
| # 2/100	|  Total error: 0.01241980462408213
| # 3/100	|  Total error: 0.009450417568065467
| # 4/100	|  Total error: 0.008000712209868916
| # 5/100	|  Total error: 0.007143459931159666
| # 6/100	|  Total error: 0.006578076850763177
| # 7/100	|  Total error: 0.006177712766940935
| # 8/100	|  Total error: 0.0058796181132721274
| # 9/100	|  Total error: 0.005649221767214015
| # 10/100	|  Total error: 0.0054659243735257065
| # 11/100	|  Total error: 0.005316695428188011
| # 12/100	|  Total error: 0.005192893732266285
| # 13/100	|  Total error: 0.00508856526638233
| # 14/100	|  Total error: 0.00499947548834243
| # 15/100	|  Total error: 0.004922531348750786
| # 16/100	|  Total error: 0.004855421540110326
| # 17/100	|  Total error: 0.004796384597803447
| # 18/100	|  Total error: 0.004744054842401955
| # 19/100	|  Total error: 0.00469735731594031
| # 20/100	|  Total error: 0.004655434462286553
| # 21/100	|  Total error: 0.004617593906740973
| # 22/100	|  Total error: 0.004583270580826859
| # 23/100	|  Total error: 0.004551998799694774
| # 24/100	|  Total error: 0.004523391371438971
| # 25/100	|  Total error: 0.00449712375719443
| # 26/100	|  Total error: 0.004472921913711545
| # 27/100	|  Total error: 0.004450552857705302
| # 28/100	|  Total error: 0.004429817267246189
| # 29/100	|  Total error: 0.00441054362537876
| # 30/100	|  Total error: 0.00439258354382581
| # 31/100	|  Total error: 0.004375807998605712
| # 32/100	|  Total error: 0.00436010427680395
| # 33/100	|  Total error: 0.0043453734826784385
| # 34/100	|  Total error: 0.004331528487199631
| # 35/100	|  Total error: 0.004318492231765611
| # 36/100	|  Total error: 0.004306196316779067
| # 37/100	|  Total error: 0.004294579820843762
| # 38/100	|  Total error: 0.004283588307822197
| # 39/100	|  Total error: 0.004273172987816315
| # 40/100	|  Total error: 0.004263290004959401
| # 41/100	|  Total error: 0.004253899830227272
| # 42/100	|  Total error: 0.004244966741651475
| # 43/100	|  Total error: 0.004236458377613151
| # 44/100	|  Total error: 0.004228345351515337
| # 45/100	|  Total error: 0.004220600918223541
| # 46/100	|  Total error: 0.004213200684345085
| # 47/100	|  Total error: 0.004206122355775707
| # 48/100	|  Total error: 0.004199345517042658
| # 49/100	|  Total error: 0.004192851437872615
| # 50/100	|  Total error: 0.004186622903147742
| # 51/100	|  Total error: 0.004180644063018848
| # 52/100	|  Total error: 0.004174900300444516
| # 53/100	|  Total error: 0.004169378113839461
| # 54/100	|  Total error: 0.0041640650128609465
| # 55/100	|  Total error: 0.004158949425649934
| # 56/100	|  Total error: 0.004154020616085996
| # 57/100	|  Total error: 0.004149268609818134
| # 58/100	|  Total error: 0.00414468412800534
| # 59/100	|  Total error: 0.00414025852784646
| # 60/100	|  Total error: 0.004135983749101793
| # 61/100	|  Total error: 0.004131852265914617
| # 62/100	|  Total error: 0.004127857043330285
| # 63/100	|  Total error: 0.004123991497987497
| # 64/100	|  Total error: 0.004120249462522559
| # 65/100	|  Total error: 0.004116625153284013
| # 66/100	|  Total error: 0.004113113141004424
| # 67/100	|  Total error: 0.004109708324118275
| # 68/100	|  Total error: 0.004106405904451782
| # 69/100	|  Total error: 0.004103201365042512
| # 70/100	|  Total error: 0.004100090449874402
| # 71/100	|  Total error: 0.004097069145338127
| # 72/100	|  Total error: 0.004094133663247979
| # 73/100	|  Total error: 0.004091280425265049
| # 74/100	|  Total error: 0.004088506048592822
| # 75/100	|  Total error: 0.004085807332825666
| # 76/100	|  Total error: 0.004083181247843284
| # 77/100	|  Total error: 0.004080624922655582
| # 78/100	|  Total error: 0.004078135635111906
| # 79/100	|  Total error: 0.004075710802397698
| # 80/100	|  Total error: 0.00407334797224924
| # 81/100	|  Total error: 0.004071044814823917
| # 82/100	|  Total error: 0.004068799115169816
| # 83/100	|  Total error: 0.004066608766243694
| # 84/100	|  Total error: 0.004064471762431314
| # 85/100	|  Total error: 0.00406238619352868
| # 86/100	|  Total error: 0.0040603502391461654
| # 87/100	|  Total error: 0.004058362163501431
| # 88/100	|  Total error: 0.004056420310570081
| # 89/100	|  Total error: 0.004054523099565583
| # 90/100	|  Total error: 0.004052669020722721
| # 91/100	|  Total error: 0.004050856631361218
| # 92/100	|  Total error: 0.004049084552207851
| # 93/100	|  Total error: 0.004047351463957687
| # 94/100	|  Total error: 0.004045656104056338
| # 95/100	|  Total error: 0.0040439972636870805
| # 96/100	|  Total error: 0.004042373784947468
| # 97/100	|  Total error: 0.004040784558202065
| # 98/100	|  Total error: 0.004039228519598281
| # 99/100	|  Total error: 0.004037704648733967
| # 100/100	|  Total error: 0.004036211966465988
Training Finish. Error = 0.004036211966465988


> Testing...
[#0] [0.11940934 0.0923233  0.44930938 0.13968468] -> [0.9848069045148231, 0.012533044903761906] (targets=[1 0]) 0, 0
[#1] [0.55132756 0.52079811 0.48542024 0.51935464] -> [0.9970213925789109, 0.0039452463713927025] (targets=[1 0]) 0, 0
[#2] [0.23990724 0.16638485 0.45562878 0.21943439] -> [0.989340536816533, 0.009788701459042053] (targets=[1 0]) 0, 0
[#3] [0.3842586  0.4163003  0.34242123 0.15775106] -> [0.9928956754123148, 0.00813739461187494] (targets=[1 0]) 0, 0
[#4] [0.21482323 0.30571525 0.38467094 0.10842893] -> [0.989415227847398, 0.010315042348540372] (targets=[1 0]) 0, 0
[#5] [0.26972408 0.47784917 0.53778099 0.32764861] -> [0.9947712541825755, 0.005615240599234531] (targets=[1 0]) 0, 0
[#6] [0.09692839 0.25769361 0.48722578 0.37396479] -> [0.9905498583375424, 0.008470876759095062] (targets=[1 0]) 0, 0
[#7] [0.62468645 0.48224552 0.68583552 1.        ] -> [0.9985047950547387, 0.0020278031438539386] (targets=[1 0]) 0, 0
[#8] [0.13015287 0.19039567 0.49264241 0.4310165 ] -> [0.9905172282195589, 0.008421350365008793] (targets=[1 0]) 0, 0
[#9] [0.50636566 0.37301319 0.53146159 0.45126066] -> [0.9959692082757909, 0.004754050351834253] (targets=[1 0]) 0, 0
[#10] [0.24038052 0.10246872 0.36544191 0.1013128 ] -> [0.9855922844844216, 0.012972568998051087] (targets=[1 0]) 0, 0
[#11] [0.25268588 0.0906324  0.45292047 0.15468376] -> [0.9874829928701665, 0.01108885525224235] (targets=[1 0]) 0, 0
[#12] [0.20961711 0.17619209 0.34269206 0.19069382] -> [0.9873099268235073, 0.01183004009796233] (targets=[1 0]) 0, 0
[#13] [0.52529699 0.41021305 0.19030423 0.20563156] -> [0.9932892301532367, 0.008658507344408447] (targets=[1 0]) 0, 0
[#14] [0.49973969 0.32499155 0.33447684 0.30801791] -> [0.9938150093241653, 0.007358392966730711] (targets=[1 0]) 0, 0
[#15] [0.64361778 0.42035847 0.34549066 0.35402736] -> [0.9958430261485944, 0.005613784004846491] (targets=[1 0]) 0, 0
[#16] [0.59392304 0.76969902 0.28500497 0.2871603 ] -> [0.9970806399081964, 0.004582747204295289] (targets=[1 0]) 0, 0
[#17] [0.15140328 0.26445722 0.48271193 0.20133734] -> [0.989827253001922, 0.009249344982299124] (targets=[1 0]) 0, 0
[#18] [0.37952577 0.19614474 0.28058138 0.27673149] -> [0.9902958757245728, 0.010274477182272757] (targets=[1 0]) 0, 0
[#19] [0.76809125 0.5836997  0.38331678 0.45647506] -> [0.9976209054075345, 0.003728478604085133] (targets=[1 0]) 0, 0
[#20] [0.49595343 1.         0.41067076 0.33869088] -> [0.9980671810430211, 0.0031301059816742373] (targets=[1 0]) 0, 0
[#21] [0.21387666 0.29556983 0.36851133 0.12431753] -> [0.9891941404854664, 0.010537893804468778] (targets=[1 0]) 0, 0
[#22] [0.23233471 0.25870815 0.63076645 0.16170787] -> [0.9918968845056514, 0.007346310142686483] (targets=[1 0]) 0, 0
[#23] [0.15471627 0.21880284 0.48271193 0.28133243] -> [0.9898702301097698, 0.009109347355132075] (targets=[1 0]) 0, 0
[#24] [0.27824317 0.12208319 0.54861425 0.21152077] -> [0.990135972615622, 0.008824707692540023] (targets=[1 0]) 0, 0
[#25] [0.43915945 0.41156578 0.57660016 0.33408993] -> [0.9956092685192055, 0.004959088796659765] (targets=[1 0]) 0, 0
[#26] [0.21245681 0.21373013 0.34422678 0.12109687] -> [0.9873393111762973, 0.011935412044054142] (targets=[1 0]) 0, 0
[#27] [0.2351744  0.17754481 0.57028076 0.31047175] -> [0.991420878510092, 0.007743232009223894] (targets=[1 0]) 0, 0
[#28] [0.32604477 0.21981738 0.31416448 0.10901172] -> [0.98875941784175, 0.011371940641932239] (targets=[1 0]) 0, 0
[#29] [0.29906763 0.40108218 0.29962986 0.1360346 ] -> [0.9912778289283815, 0.009553816456897214] (targets=[1 0]) 0, 0
[#30] [0.69709877 0.25498816 0.37203214 0.20317772] -> [0.9944383716909581, 0.006965078753747505] (targets=[1 0]) 0, 0
[#31] [0.4348999  0.21508285 0.41680961 0.38163303] -> [0.9931395431136605, 0.00737472799226433] (targets=[1 0]) 0, 0
[#32] [0.08296654 0.24112276 0.46285095 0.16839458] -> [0.9878286301294676, 0.010564647807910063] (targets=[1 0]) 0, 0
[#33] [0.69236594 0.425093   0.57840571 0.58070057] -> [0.9975588329959576, 0.0032752741846144556] (targets=[1 0]) 0, 0
[#34] [0.282976   0.29015894 0.18849869 0.18284154] -> [0.9885226998517764, 0.012231285588179187] (targets=[1 0]) 0, 0
[#35] [0.37905249 0.41934393 0.29358129 0.25495368] -> [0.9931082629026455, 0.008075152501655917] (targets=[1 0]) 0, 0
[#36] [0.21908278 0.21339195 0.50708676 0.29881602] -> [0.991021739809907, 0.008299966639704694] (targets=[1 0]) 0, 0
[#37] [0.16560178 0.17822117 0.41103187 0.25127293] -> [0.9881913302196936, 0.010641023618365133] (targets=[1 0]) 0, 0
[#38] [0.19636519 0.23368279 0.26072041 0.05815594] -> [0.9854763874385511, 0.013909796095214545] (targets=[1 0]) 0, 0
[#39] [0.37479294 0.43354751 0.42285817 0.62302926] -> [0.9957602540085679, 0.005032148374315] (targets=[1 0]) 0, 0
[#40] [0.56031994 0.4146094  0.44389275 0.36660328] -> [0.9958322854946806, 0.005234264814471111] (targets=[1 0]) 0, 0
[#41] [0.26688438 0.25160636 0.29972014 0.10710999] -> [0.9882089207246334, 0.011774238213517522] (targets=[1 0]) 0, 0
[#42] [0.3028539  0.71051742 0.35948361 0.16833323] -> [0.9951295027598188, 0.0061329336485733705] (targets=[1 0]) 0, 0
[#43] [0.13128875 0.62529591 0.24564413 0.08244893] -> [0.9914155175996372, 0.009643505792022326] (targets=[1 0]) 0, 0
[#44] [0.35112878 0.58437606 0.15636003 0.10076069] -> [0.9926252191152869, 0.009386933050590272] (targets=[1 0]) 0, 0
[#45] [0.29291495 0.28779168 0.19888056 0.12440955] -> [0.9881664180549523, 0.012545745671434731] (targets=[1 0]) 0, 0
[#46] [0.36248758 0.24146094 0.30495622 0.14600331] -> [0.9898844999939235, 0.010616208443020182] (targets=[1 0]) 0, 0
[#47] [0.76241185 0.34223876 0.3682405  0.3316361 ] -> [0.9960225405772437, 0.005469948067496059] (targets=[1 0]) 0, 0
[#48] [0.18831937 0.26750085 0.39938612 0.23967855] -> [0.9897998640497706, 0.009728037214896302] (targets=[1 0]) 0, 0
[#49] [0.03540158 0.53364897 0.25593572 0.09017852] -> [0.988933213934781, 0.011275084910429875] (targets=[1 0]) 0, 0
[#50] [0.32604477 0.37166047 0.38954591 0.25280658] -> [0.9928072265092444, 0.007801264004124582] (targets=[1 0]) 0, 0
[#51] [0.15518955 0.23233006 0.32626162 0.18796393] -> [0.9872271921271685, 0.011926311292038357] (targets=[1 0]) 0, 0
[#52] [0.27398362 0.66689212 0.27200506 0.07042513] -> [0.9934875878015633, 0.007997495924459383] (targets=[1 0]) 0, 0
[#53] [0.1566094  0.60534325 0.34007403 0.17544936] -> [0.992895327953067, 0.007901119949295557] (targets=[1 0]) 0, 0
[#54] [0.21434995 0.4808928  0.36092805 0.25372677] -> [0.9927251714687818, 0.007888799654954292] (targets=[1 0]) 0, 0
[#55] [0.45525108 0.62123774 0.28816467 0.25434022] -> [0.9954369877209764, 0.006152276010148696] (targets=[1 0]) 0, 0
Testing Finish. Error: 0.00015848491370919372

Testing accuracy: 1.0
```

### References
1. [Neural network implementation - towardsdatascience](https://towardsdatascience.com/the-ultimate-beginners-guide-to-implement-a-neural-network-from-scratch-cf7d52d91e00)
1. [Neural network - kaggle](https://www.kaggle.com/antmarakis/another-neural-network-from-scratch)
1. [Neural netwrok backpropagation](https://github.com/Vercaca/NN-Backpropagation)
1. [Simple neural network in python](https://www.kaggle.com/ancientaxe/simple-neural-network-from-scratch-in-python)
 

